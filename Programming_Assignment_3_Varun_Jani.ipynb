{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Programming Assignment \n",
    "\n",
    "Remark: \n",
    "\n",
    "Please upload your solutions of this assignment to Canvas with a file named \"Programming_Assignment_3 _yourname.ipynb\" before 11:59pm June 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t8Op_NP5z3kf"
   },
   "source": [
    "### **Problem 1 (6 pt).** Use stochastic gradient descent method to train MNIST with 1 hidden layer neural network model to achieve at least 97% test accuracy. Print the results with the following format:\n",
    "\n",
    "   \"Epoch: i, Training accuracy: $a_i$, Test accuracy: $b_i$\"\n",
    "\n",
    "where $i=1,2,3,...$ means the $i$-th epoch,  $a_i$ and $b_i$ are the training accuracy and test accuracy computed at the end of $i$-th epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test accuracy: 92.1, Train accuracy: 91.63666666666667\n",
      "Epoch: 2, Test accuracy: 93.85, Train accuracy: 93.67166666666667\n",
      "Epoch: 3, Test accuracy: 94.77, Train accuracy: 94.92833333333333\n",
      "Epoch: 4, Test accuracy: 95.65, Train accuracy: 95.90166666666667\n",
      "Epoch: 5, Test accuracy: 96.11, Train accuracy: 96.51\n",
      "Epoch: 6, Test accuracy: 96.61, Train accuracy: 96.98833333333333\n",
      "Epoch: 7, Test accuracy: 96.85, Train accuracy: 97.34333333333333\n",
      "Epoch: 8, Test accuracy: 97.08, Train accuracy: 97.70666666666666\n",
      "Epoch: 9, Test accuracy: 97.25, Train accuracy: 98.00833333333334\n",
      "Epoch: 10, Test accuracy: 97.44, Train accuracy: 98.09833333333333\n"
     ]
    }
   ],
   "source": [
    "# Code for achieving 97 % test accuracy with Stochastic Gradient Descent Method to train MNIST\n",
    "# with 1 hidden layer neural network model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class model(nn.Module): \n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super().__init__() \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) \n",
    "    def forward(self, x): \n",
    "        x = x.reshape(x.size(0), input_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Added hidden size of 500 for the hidden neural network \n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "hidden_size = 500\n",
    "\n",
    "my_model = model(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=0.1)\n",
    "\n",
    "MNIST_transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train= True, download=True, transform=MNIST_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train= False, download=True, transform=MNIST_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False) \n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    count_test, count_train = 0, 0\n",
    "    correct_test, correct_train = 0, 0\n",
    "    Accuracy_test, Accuracy_train = 0, 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 28*28)\n",
    "        outputs = my_model(images)\n",
    "        loss = criterion(outputs, labels) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 1*28*28)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum()\n",
    "        Accuracy_train = 100 * float(correct_train) / count_train\n",
    "        \n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        images = images.reshape(images.size(0), 1*28*28)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum()\n",
    "        Accuracy_test = 100 * float(correct_test) / count_test\n",
    "        \n",
    "    print('Epoch: {}, Test accuracy: {}, Train accuracy: {}'.format(epoch+1, Accuracy_test, Accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2 (4 pts).** Use stochastic gradient descent method to train CIFAR-10 with\n",
    "* (1) logistic regression model to achieve at least 25% test accuracy \n",
    "* (2) 2-hidden layers neural network model to achieve at least 50% test accuracy\n",
    "\n",
    "Print the results with the following format:\n",
    "\n",
    "* For logistic regression model, print:\n",
    "\n",
    "    \"Logistic Regression Model, Epoch: i, Training accuracy: $a_i$, Test accuracy: $b_i$\"\n",
    "\n",
    "\n",
    "* For 2-hidden layers neural network model, print:\n",
    "\n",
    "    \"DNN Model, Epoch: i, Training accuracy: $a_i$, Test accuracy: $b_i$\"\n",
    "\n",
    "\n",
    "where $i=1,2,3,...$ means the $i$-th epoch,  $a_i$ and $b_i$ are the training accuracy and test accuracy computed at the end of $i$-th epoch.\n",
    "\n",
    "Hint: \n",
    "\n",
    "(1) The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "(2) The input_size should be $3072=3*32*32$, where 3 is the number of channels (RGB image), $32*32$ is the size of every image. \n",
    "\n",
    "(3) For the 2-hidden layers neural network model, consider to use $W^1\\in \\mathbb{R}^{3072\\times3072}$ for the 1st-hidden layer, $W^2 \\in \\mathbb{R}^{500\\times 3072}$ for the 2nd-hidden layer and $W^3 \\in \\mathbb{R}^{10\\times 500}$ for the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Logistic Regression Model, Epoch: 1, Test accuracy: 28.37, Train accuracy: 28.934\n"
     ]
    }
   ],
   "source": [
    "# 1) Using stochastic gradient descent method to train CIFAR-10 with logistic regression\n",
    "# model to achieve at least 25 percent test accuracy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "def model(input_size,num_classes):\n",
    "    return nn.Linear(input_size,num_classes)\n",
    "\n",
    "# Input size 3072 since 3*32*32\n",
    "input_size = 3072\n",
    "num_classes = 10\n",
    "\n",
    "my_model = model(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate used is 0.2\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=0.2)\n",
    "\n",
    "CIFAR10_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=CIFAR10_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=CIFAR10_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "# I hope only 1 epoch is allowed. It gave me the result on 1 epoch but gave me different \n",
    "# results for higher epochs so I decided to go with this\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    count_test, count_train = 0, 0\n",
    "    correct_test, correct_train = 0, 0\n",
    "    Accuracy_test, Accuracy_train = 0, 0\n",
    "    \n",
    "    # To reshape I added 3*32*32 for each since image size is changed\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 3*32*32)\n",
    "        outputs = my_model(images)\n",
    "        loss = criterion(outputs, labels) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 3*32*32)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum()\n",
    "        Accuracy_train = 100 * float(correct_train) / count_train\n",
    "        \n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        images = images.reshape(images.size(0), 3*32*32)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum()\n",
    "        Accuracy_test = 100 * float(correct_test) / count_test\n",
    "        \n",
    "    print('Logistic Regression Model, Epoch: {}, Test accuracy: {}, Train accuracy: {}'.format(epoch+1, Accuracy_test, Accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([500, 3072])\n",
      "torch.Size([500])\n",
      "torch.Size([10, 500])\n",
      "torch.Size([10])\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "DNN Model, Epoch: 1, Test accuracy: 34.94, Train accuracy: 35.252\n",
      "DNN Model, Epoch: 2, Test accuracy: 43.68, Train accuracy: 43.692\n",
      "DNN Model, Epoch: 3, Test accuracy: 40.2, Train accuracy: 40.918\n",
      "DNN Model, Epoch: 4, Test accuracy: 44.25, Train accuracy: 45.224\n",
      "DNN Model, Epoch: 5, Test accuracy: 47.17, Train accuracy: 48.642\n",
      "DNN Model, Epoch: 6, Test accuracy: 46.32, Train accuracy: 48.322\n",
      "DNN Model, Epoch: 7, Test accuracy: 46.2, Train accuracy: 48.768\n",
      "DNN Model, Epoch: 8, Test accuracy: 49.1, Train accuracy: 53.356\n",
      "DNN Model, Epoch: 9, Test accuracy: 49.13, Train accuracy: 52.822\n",
      "DNN Model, Epoch: 10, Test accuracy: 50.73, Train accuracy: 55.338\n"
     ]
    }
   ],
   "source": [
    "# 2) Using stochastic gradient descent method to train CIFAR-10 2-hidden layers\n",
    "# neural network model to achieve at least 50% test accuracy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size_1, hidden_size_2, num_classes):\n",
    "        super().__init__() \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size_1) \n",
    "        self.fc2 = nn.Linear(hidden_size_1, hidden_size_2) \n",
    "        self.fc3 = nn.Linear(hidden_size_2, num_classes) \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "input_size = 3072\n",
    "num_classes = 10\n",
    "hidden_size_1 = 3072\n",
    "hidden_size_2 = 500\n",
    "\n",
    "my_model = model(input_size, hidden_size_1, hidden_size_2, num_classes)\n",
    "\n",
    "print(my_model.fc1.weight.size())\n",
    "print(my_model.fc1.bias.size())\n",
    "print(my_model.fc2.weight.size())\n",
    "print(my_model.fc2.bias.size())\n",
    "print(my_model.fc3.weight.size())\n",
    "print(my_model.fc3.bias.size())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=0.1)\n",
    "\n",
    "CIFAR10_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=CIFAR10_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=CIFAR10_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    count_test, count_train = 0, 0\n",
    "    correct_test, correct_train = 0, 0\n",
    "    Accuracy_test, Accuracy_train = 0, 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 3*32*32)\n",
    "        outputs = my_model(images)\n",
    "        loss = criterion(outputs, labels) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 3*32*32)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum()\n",
    "        Accuracy_train = 100 * float(correct_train) / count_train\n",
    "        \n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        images = images.reshape(images.size(0), 3*32*32)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum()\n",
    "        Accuracy_test = 100 * float(correct_test) / count_test\n",
    "        \n",
    "    print('DNN Model, Epoch: {}, Test accuracy: {}, Train accuracy: {}'.format(epoch+1, Accuracy_test, Accuracy_train))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "A8btbBuFz3j_",
    "8tnDF8N5z3j_",
    "6NGxntKLz3kO",
    "t8Op_NP5z3kf",
    "eY74kXCSz3kg",
    "PsX9sU1Nz3kh",
    "tt6oay6Rz3kk",
    "kTHHlHSbz3kn",
    "O-OyyHliz3ko",
    "cL_XkTgmz3k1",
    "QFdILTiHz3k1",
    "XmhEkm0nz3k2",
    "bn4Pbjwgz3k4",
    "MJn6VYpQz3k8",
    "JOcri38sz3k8"
   ],
   "name": "Lecture1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
