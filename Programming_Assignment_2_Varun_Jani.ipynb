{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Programming Assignment \n",
    "\n",
    "Remark: \n",
    "\n",
    "Please upload your solutions of this assignment to Canvas with a file named \"Programming_Assignment_2 _yourname.ipynb\" before 11:59pm May 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t8Op_NP5z3kf"
   },
   "source": [
    "### **Problem 1 (4 pt).** Use stochastic gradient descent method to train MNIST with the logisitc regression model to achieve at least 92% test accuracy. Print the results with the following format:\n",
    "\n",
    "   \"Epoch: i, Training accuracy: $a_i$, Test accuracy: $b_i$\"\n",
    "\n",
    "where $i=1,2,3,...$ means the $i$-th epoch,  $a_i$ and $b_i$ are the training accuracy and test accuracy computed at the end of $i$-th epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test accuracy: 90.24, Train accuracy: 89.66166666666666\n",
      "Epoch: 2, Test accuracy: 91.13, Train accuracy: 90.54333333333334\n",
      "Epoch: 3, Test accuracy: 91.4, Train accuracy: 91.11\n",
      "Epoch: 4, Test accuracy: 91.94, Train accuracy: 91.505\n",
      "Epoch: 5, Test accuracy: 91.86, Train accuracy: 91.61666666666666\n",
      "Epoch: 6, Test accuracy: 91.89, Train accuracy: 91.74166666666666\n",
      "Epoch: 7, Test accuracy: 92.12, Train accuracy: 91.9\n",
      "Epoch: 8, Test accuracy: 91.98, Train accuracy: 92.02166666666666\n",
      "Epoch: 9, Test accuracy: 92.12, Train accuracy: 92.08\n",
      "Epoch: 10, Test accuracy: 92.1, Train accuracy: 92.12833333333333\n"
     ]
    }
   ],
   "source": [
    "# Code for achieving 92 % test accuracy with Stochastic Gradient Descent Method to train MNIST\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "def model(input_size,num_classes):\n",
    "    return nn.Linear(input_size,num_classes)\n",
    "\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "\n",
    "my_model = model(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=0.1)\n",
    "\n",
    "MNIST_transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train= True, download=True, transform=MNIST_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train= False, download=True, transform=MNIST_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False) \n",
    "\n",
    "# Works for num_epoch = 7 also, but I decided to go with 10\n",
    "# to test what happens with train accuracy\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    count_test, count_train = 0, 0\n",
    "    correct_test, correct_train = 0, 0\n",
    "    Accuracy_test, Accuracy_train = 0, 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 28*28)\n",
    "        outputs = my_model(images)\n",
    "        loss = criterion(outputs, labels) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 1*28*28)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum()\n",
    "        Accuracy_train = 100 * float(correct_train) / count_train\n",
    "        \n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        images = images.reshape(images.size(0), 1*28*28)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum()\n",
    "        Accuracy_test = 100 * float(correct_test) / count_test\n",
    "        \n",
    "    print('Epoch: {}, Test accuracy: {}, Train accuracy: {}'.format(epoch+1, Accuracy_test, Accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2 (6 pts).** Extract the subset of data which are labeled with 0,1,3,4,7 from MNIST dataset. Use both full gradient descent method and stochastic gradient descent method to train this subset with the logisitc regression model to achieve the training and test accuracy as high as possible. Print the results with the following format:\n",
    "\n",
    "* For full gradient descent method, print:\n",
    "\n",
    "    \"Full gradient descent, Epoch: i, Training accuracy: $a_i$, Test accuracy: $b_i$\"\n",
    "\n",
    "\n",
    "* For stochastic gradient descent method, print:\n",
    "\n",
    "    \"Stochastic gradient descent, Epoch: i, Training accuracy: $a_i$, Test accuracy: $b_i$\"\n",
    "\n",
    "where $i=1,2,3,...$ means the $i$-th epoch,  $a_i$ and $b_i$ are the training accuracy and test accuracy computed at the end of $i$-th epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent Method, Epoch: 1, Test accuracy: 97.56572541382668, Train accuracy: 97.00999902922047\n",
      "Stochastic Gradient Descent Method, Epoch: 2, Test accuracy: 97.8188899707887, Train accuracy: 97.42096236611333\n",
      "Stochastic Gradient Descent Method, Epoch: 3, Test accuracy: 97.95520934761441, Train accuracy: 97.6151182733068\n",
      "Stochastic Gradient Descent Method, Epoch: 4, Test accuracy: 98.09152872444011, Train accuracy: 97.74779147655568\n",
      "Stochastic Gradient Descent Method, Epoch: 5, Test accuracy: 98.18889970788705, Train accuracy: 97.877228748018\n",
      "Stochastic Gradient Descent Method, Epoch: 6, Test accuracy: 98.18889970788705, Train accuracy: 97.87399281623144\n",
      "Stochastic Gradient Descent Method, Epoch: 7, Test accuracy: 98.1110029211295, Train accuracy: 97.96783483804161\n",
      "Stochastic Gradient Descent Method, Epoch: 8, Test accuracy: 98.16942551119766, Train accuracy: 98.03902533734589\n",
      "Stochastic Gradient Descent Method, Epoch: 9, Test accuracy: 98.24732229795521, Train accuracy: 98.07785651878459\n",
      "Stochastic Gradient Descent Method, Epoch: 10, Test accuracy: 98.16942551119766, Train accuracy: 98.08756431414426\n",
      "Stochastic Gradient Descent Method, Epoch: 11, Test accuracy: 98.34469328140214, Train accuracy: 98.15551888166198\n",
      "Stochastic Gradient Descent Method, Epoch: 12, Test accuracy: 98.28627069133398, Train accuracy: 98.11021583665017\n",
      "Stochastic Gradient Descent Method, Epoch: 13, Test accuracy: 98.2667964946446, Train accuracy: 98.184642267741\n",
      "Stochastic Gradient Descent Method, Epoch: 14, Test accuracy: 98.2667964946446, Train accuracy: 98.23318124453937\n",
      "Stochastic Gradient Descent Method, Epoch: 15, Test accuracy: 98.32521908471276, Train accuracy: 98.22023751739313\n",
      "Stochastic Gradient Descent Method, Epoch: 16, Test accuracy: 98.44206426484908, Train accuracy: 98.2687764941915\n",
      "Stochastic Gradient Descent Method, Epoch: 17, Test accuracy: 98.46153846153847, Train accuracy: 98.2849561531243\n",
      "Stochastic Gradient Descent Method, Epoch: 18, Test accuracy: 98.38364167478092, Train accuracy: 98.28172022133774\n",
      "Stochastic Gradient Descent Method, Epoch: 19, Test accuracy: 98.38364167478092, Train accuracy: 98.33673106170922\n",
      "Stochastic Gradient Descent Method, Epoch: 20, Test accuracy: 98.34469328140214, Train accuracy: 98.33673106170922\n"
     ]
    }
   ],
   "source": [
    "# The next two segments of the code is for a specific subset of MNIST dataset\n",
    "\n",
    "# Code for achieving 98 % test accuracy with Stochastic Gradient Descent Method\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "def get_indices(dataset):\n",
    "    indices =  []\n",
    "    for i in range(len(dataset.targets)):\n",
    "        if dataset.targets[i] == 0:\n",
    "            dataset.targets[i] = 0\n",
    "            indices.append(i)\n",
    "        elif dataset.targets[i] == 1:\n",
    "            dataset.targets[i] = 1\n",
    "            indices.append(i)\n",
    "        elif dataset.targets[i] == 3:\n",
    "            dataset.targets[i] = 2\n",
    "            indices.append(i)\n",
    "        elif dataset.targets[i] == 4:\n",
    "            dataset.targets[i] = 3\n",
    "            indices.append(i)\n",
    "        elif dataset.targets[i] == 7:\n",
    "            dataset.targets[i] = 4\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "def model(input_size,num_classes):\n",
    "    return nn.Linear(input_size,num_classes)\n",
    "\n",
    "input_size = 784\n",
    "num_classes = 5\n",
    "\n",
    "my_model = model(input_size,num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=0.25)\n",
    "\n",
    "MNIST_transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train= True, download=True, transform=MNIST_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200, sampler=torch.utils.data.sampler.SubsetRandomSampler(get_indices(trainset)))\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train= False, download=True, transform=MNIST_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, sampler=torch.utils.data.sampler.SubsetRandomSampler(get_indices(testset)))\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct_train, correct_test = 0, 0\n",
    "    count_train, count_test = 0, 0\n",
    "    Accuracy_test, Accuracy_train = 0, 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 28*28)\n",
    "        outputs = my_model(images)\n",
    "        loss = criterion(outputs, labels) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 1*28*28)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum()\n",
    "        Accuracy_train = 100 * float(correct_train) / count_train\n",
    "        \n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        images = images.reshape(images.size(0), 1*28*28)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum()\n",
    "        Accuracy_test = 100 * float(correct_test) / count_test\n",
    "\n",
    "    print('Stochastic Gradient Descent Method, Epoch: {}, Test accuracy: {}, Train accuracy: {}'.format(epoch+1, Accuracy_test, Accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Gradient Descent Method, Epoch: 1, Test accuracy: 83.0379746835443, Train accuracy: 81.19923632009838\n",
      "Full Gradient Descent Method, Epoch: 2, Test accuracy: 93.16455696202532, Train accuracy: 91.88104714752613\n",
      "Full Gradient Descent Method, Epoch: 3, Test accuracy: 93.94352482960078, Train accuracy: 92.87124227421286\n",
      "Full Gradient Descent Method, Epoch: 4, Test accuracy: 94.76144109055501, Train accuracy: 93.6996408115717\n",
      "Full Gradient Descent Method, Epoch: 5, Test accuracy: 95.01460564751704, Train accuracy: 93.99087467236191\n",
      "Full Gradient Descent Method, Epoch: 6, Test accuracy: 95.24829600778968, Train accuracy: 94.17855871598226\n",
      "Full Gradient Descent Method, Epoch: 7, Test accuracy: 95.42356377799416, Train accuracy: 94.3144678510177\n",
      "Full Gradient Descent Method, Epoch: 8, Test accuracy: 95.55988315481986, Train accuracy: 94.4374332589069\n",
      "Full Gradient Descent Method, Epoch: 9, Test accuracy: 95.69620253164557, Train accuracy: 94.56687053036921\n",
      "Full Gradient Descent Method, Epoch: 10, Test accuracy: 95.69620253164557, Train accuracy: 94.67042034753908\n",
      "Full Gradient Descent Method, Epoch: 11, Test accuracy: 95.7935735150925, Train accuracy: 94.75131864220302\n",
      "Full Gradient Descent Method, Epoch: 12, Test accuracy: 95.92989289191821, Train accuracy: 94.81603727793419\n",
      "Full Gradient Descent Method, Epoch: 13, Test accuracy: 96.02726387536514, Train accuracy: 94.88722777723845\n",
      "Full Gradient Descent Method, Epoch: 14, Test accuracy: 96.0856864654333, Train accuracy: 94.95518234475617\n",
      "Full Gradient Descent Method, Epoch: 15, Test accuracy: 96.16358325219085, Train accuracy: 95.03931657120668\n",
      "Full Gradient Descent Method, Epoch: 16, Test accuracy: 96.18305744888023, Train accuracy: 95.09432741157816\n",
      "Full Gradient Descent Method, Epoch: 17, Test accuracy: 96.22200584225901, Train accuracy: 95.16875384266899\n",
      "Full Gradient Descent Method, Epoch: 18, Test accuracy: 96.2414800389484, Train accuracy: 95.22052875125392\n",
      "Full Gradient Descent Method, Epoch: 19, Test accuracy: 96.26095423563778, Train accuracy: 95.26906772805229\n",
      "Full Gradient Descent Method, Epoch: 20, Test accuracy: 96.28042843232717, Train accuracy: 95.3305504319969\n"
     ]
    }
   ],
   "source": [
    "# Code for achieving 96 % test accuracy with Full Gradient Descent Method\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "def get_indices(dataset):\n",
    "    indices =  []\n",
    "    for i in range(len(dataset.targets)):\n",
    "        if dataset.targets[i] == 0:\n",
    "            dataset.targets[i] = 0\n",
    "            indices.append(i)\n",
    "        elif dataset.targets[i] == 1:\n",
    "            dataset.targets[i] = 1\n",
    "            indices.append(i)\n",
    "        elif dataset.targets[i] == 3:\n",
    "            dataset.targets[i] = 2\n",
    "            indices.append(i)\n",
    "        elif dataset.targets[i] == 4:\n",
    "            dataset.targets[i] = 3\n",
    "            indices.append(i)\n",
    "        elif dataset.targets[i] == 7:\n",
    "            dataset.targets[i] = 4\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "def model(input_size,num_classes):\n",
    "    return nn.Linear(input_size,num_classes)\n",
    "\n",
    "input_size = 784\n",
    "num_classes = 5\n",
    "\n",
    "my_model = model(input_size,num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=0.25)\n",
    "\n",
    "MNIST_transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train= True, download=True, transform=MNIST_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=60000, sampler=torch.utils.data.sampler.SubsetRandomSampler(get_indices(trainset)))\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train= False, download=True, transform=MNIST_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, sampler=torch.utils.data.sampler.SubsetRandomSampler(get_indices(testset)))\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct_train, correct_test = 0, 0\n",
    "    count_train, count_test = 0, 0\n",
    "    Accuracy_test, Accuracy_train = 0, 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 28*28)\n",
    "        outputs = my_model(images)\n",
    "        loss = criterion(outputs, labels) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.reshape(images.size(0), 1*28*28)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum()\n",
    "        Accuracy_train = 100 * float(correct_train) / count_train\n",
    "        \n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        images = images.reshape(images.size(0), 1*28*28)\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        count_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum()\n",
    "        Accuracy_test = 100 * float(correct_test) / count_test\n",
    "\n",
    "    print('Full Gradient Descent Method, Epoch: {}, Test accuracy: {}, Train accuracy: {}'.format(epoch+1, Accuracy_test, Accuracy_train))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "A8btbBuFz3j_",
    "8tnDF8N5z3j_",
    "6NGxntKLz3kO",
    "t8Op_NP5z3kf",
    "eY74kXCSz3kg",
    "PsX9sU1Nz3kh",
    "tt6oay6Rz3kk",
    "kTHHlHSbz3kn",
    "O-OyyHliz3ko",
    "cL_XkTgmz3k1",
    "QFdILTiHz3k1",
    "XmhEkm0nz3k2",
    "bn4Pbjwgz3k4",
    "MJn6VYpQz3k8",
    "JOcri38sz3k8"
   ],
   "name": "Lecture1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
